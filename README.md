ğŸ”‘ Concept Dictionary

AI (Artificial Intelligence) â€“ Computers doing tasks that normally need human intelligence (e.g., recognizing patterns, making predictions).

ML (Machine Learning) â€“ A part of AI where computers learn from examples instead of being given explicit rules.

Project (Big Picture) â€“
â€œWe use data from the past, teach a computer program (a model) to spot patterns, and then use that model to make predictions about the future.â€

Wildfire Use Case â€“ Using weather + land data to predict where fires are likely to happen and how bad they might be.

Mental Health Use Case â€“ Using phone + behavior data (steps, sleep, time at home, calls, screen time) to estimate a personâ€™s depression risk.

Dataset â€“ A big table of examples. Each row = one example (one week, one location, etc.).

Feature â€“ An input column used to make a prediction.

Wildfires: temperature, humidity, wind speed, rain, vegetation, population, month, year.

Mental health: steps, time at home, sleep hours, screen time, etc.

Label / Target â€“ What we want the model to predict.

Wildfires: fire_occurred (yes/no), burned_area.

Mental health: depression_score, high_risk (yes/no).

Model â€“ A mathematical formula/program that uses features to predict the label.

Training a Model â€“ Feeding the model many labeled examples from the past so it can adjust itself and learn the relationship between features and labels.

Testing a Model â€“ Giving the trained model new examples it has never seen to check how accurate its predictions are.

Regression â€“ Type of ML task where we predict a number.

Example: predict depression_score (0â€“27).

In this project: mental health regression.

Classification â€“ Type of ML task where we predict a category.

Examples: fire_occurred = 0/1, high_risk = yes/no.

In this project: wildfire classification, mental health high-risk classification.

Neural Network â€“ A more complex ML model inspired by the brain; great for images and sequences.

Example: CNNs (Convolutional Neural Networks) for detecting smoke/flames in wildfire photos (notebooks mention this idea, even if they use simpler models).

Simple Models (in notebooks) â€“ Logistic Regression, Random Forest, Gradient Boosting: easier to train, explain, and good for tabular data.

ROC Curve â€“ A graph showing how well a classification model separates positive vs negative cases across different thresholds.

AUC (Area Under the ROC Curve) â€“ A single number summarizing how good the ROC curve is; closer to 1.0 = better.

SHAP â€“ A tool to explain model predictions by showing which features push the prediction up or down.

Git â€“ A tool that tracks changes to code over time (version control).

GitHub â€“ A website where Git projects are stored and shared; used here to host and share notebooks and code.

ğŸ›  Tool & Notebook Dictionary
Languages & Libraries

Python â€“ The main programming language used for all AI/ML code in this project.

Jupyter Notebook â€“ A â€œdigital workbookâ€ for Python with cells where you:

Write code

Run it

See results (tables, charts) immediately below

Pandas â€“ Python library for working with tabular data (like Excel in code).

Reads CSV files (e.g., wildfire_synthetic.csv, mental_health_mobile_sensing_synthetic.csv).

Lets you filter rows, select columns, compute averages, etc.

NumPy â€“ Python library for numbers and arrays.

Used for fast math operations that ML models rely on.

Scikit-Learn (sklearn) â€“ Python library for machine learning.

Split data into training/test sets.

Train models (logistic regression, random forest, gradient boosting).

Measure performance (accuracy, precision, recall, F1, ROC-AUC, MAE, RMSE, RÂ²).

Notebooks (Step-by-Step Story)

00_environment_setup.ipynb â€“
â€œGet tools ready.â€

Imports Python libraries (NumPy, Pandas, Matplotlib, Scikit-Learn).

Ensures the environment and project structure (data/raw, notebooks, models) are set up.

10_wildfire_data_and_eda.ipynb â€“
â€œUnderstand wildfire data.â€

Uses wildfire_synthetic.csv.

Loads data with Pandas.

Shows first rows and summary stats.

Checks class balance for fire_occurred (how many 1s vs 0s).

Plots simple charts (e.g., temperature vs fire occurrence).

Purpose: understand the data before training any model.

20_wildfire_ml_models.ipynb â€“
â€œBuild wildfire prediction models.â€

Features: temp_c, humidity, wind_speed, rain_mm_last_7d, vegetation_index, population_density, month, year.

Uses train_test_split (Scikit-Learn) â†’ training set + test set.

Trains:

Logistic Regression (simple, interpretable).

Random Forest (more flexible).

Evaluates with: Accuracy, Precision, Recall, F1, ROC-AUC.

Plots feature importances for Random Forest.

Story: â€œWe feed weather + land features into Python and learn to predict fire risk.â€

30_mental_health_data_and_eda.ipynb â€“
â€œUnderstand mental health data.â€

Uses mental_health_mobile_sensing_synthetic.csv.

Loads behavior data (steps, distance, time at home, calls/texts, sleep, screen time) with Pandas.

Shows distributions of depression_score and high_risk.

Plots relationships (e.g., steps vs depression score).

Story: â€œWe convert weekly phone/behavior logs into numbers and see how they relate to mental health scores.â€

40_mental_health_ml_models.ipynb â€“
â€œBuild mental health prediction models.â€

Features: steps, distance, time at home, calls/texts, sleep, screen time, etc.

Splits data into training/test sets.

Trains:

Gradient Boosting Regressor â†’ predicts depression_score (regression).

Random Forest Classifier â†’ predicts high_risk (classification).

Evaluates:

Regression: MAE, RMSE, RÂ².

Classification: Accuracy, Precision, Recall, F1, ROC-AUC.

Plots feature importances to see which behaviors are most linked to risk.

Story: â€œGiven weekly behavior, can we guess mental health scores and high-risk weeks?â€

50_model_evaluation_and_explainability.ipynb â€“
â€œCompare and explain models.â€

Trains quick Random Forest models for:

Wildfire (fire_occurred).

Mental health (high_risk).

Plots ROC curves for both; computes AUC.

Optionally uses SHAP for feature-level explanations.

Story: â€œWe check how strong the models are and explain why they predict what they do.â€

60_serving_and_automation.ipynb â€“
â€œUse models in the real world.â€

Trains a wildfire model again.

Does batch scoring: adds a risk_score to all rows.

Defines predict_fire_risk(...) function in Python that returns a probability of fire given new conditions.

Can be called from web apps, dashboards, or mobile apps.

Story: â€œThe model leaves the lab and becomes a tool other systems can call.â€

Learning Roadmap (as a mini-dictionary entry)

Suggested Notebook Order â€“

00_environment_setup.ipynb â€“ tools ready

10_wildfire_data_and_eda.ipynb â€“ understand wildfire data

20_wildfire_ml_models.ipynb â€“ build wildfire models

30_mental_health_data_and_eda.ipynb â€“ understand mental health data

40_mental_health_ml_models.ipynb â€“ build mental health models

50_model_evaluation_and_explainability.ipynb â€“ compare & explain

60_serving_and_automation.ipynb â€“ use models as a service

You can literally print this and give it as a keyword dictionary for the session.